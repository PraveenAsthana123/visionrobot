% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={07 Demo Scenarios},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{07 Demo Scenarios}
\author{}
\date{}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{3}
\tableofcontents
}
\hypertarget{demo-scenarios---vision-based-pick-and-place-system}{%
\section{Demo Scenarios - Vision-Based Pick and Place
System}\label{demo-scenarios---vision-based-pick-and-place-system}}

\hypertarget{overview}{%
\subsection{Overview}\label{overview}}

This document outlines demonstration scenarios organized by priority
using the \textbf{MoSCoW method}: - \textbf{Must Have:} Essential
scenarios for MVP validation - \textbf{Should Have:} Important scenarios
for production-readiness - \textbf{May Have:} Advanced scenarios
showcasing full capabilities

Each scenario includes: setup, execution steps, success criteria, and
robotics concepts demonstrated.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{must-have-demo-scenarios}{%
\subsection{1. Must Have Demo
Scenarios}\label{must-have-demo-scenarios}}

\hypertarget{scenario-m1-basic-pick-and-place-single-object}{%
\subsubsection{Scenario M1: Basic Pick and Place (Single
Object)}\label{scenario-m1-basic-pick-and-place-single-object}}

\textbf{Objective:} Demonstrate end-to-end workflow with a single known
object

\textbf{Setup:} - Robot: UR5e with Robotiq 2F-85 gripper - Object: Red
cube (50mm × 50mm × 50mm) on white table - Camera: RealSense D435i
mounted eye-to-hand (above workspace) - Lighting: Uniform LED lighting
(5000K, 2000 lumen) - Target: Marked drop zone (300mm from pick zone)

\textbf{Execution Steps:} 1. Start system: Press ``Start'' button on HMI
2. \textbf{Scan:} Camera captures RGB-D image, displays in RViz2 3.
\textbf{Detect:} YOLO detects cube, bounding box overlays on image 4.
\textbf{Localize:} Pose estimation outputs (x,y,z) = (0.4m, 0.2m, 0.05m)
5. \textbf{Plan Grasp:} Compute top-down grasp, gripper opens to 80mm 6.
\textbf{Plan Pick:} MoveIt plans trajectory (home → pre-grasp → grasp)
7. \textbf{Execute Pick:} Robot moves, gripper closes, F/T sensor
confirms grasp (20N) 8. \textbf{Plan Place:} Plan trajectory (pick →
pre-place → place) 9. \textbf{Execute Place:} Robot moves to target,
gripper opens, object released 10. \textbf{Return:} Robot returns to
home position

\textbf{Success Criteria:} - ✅ Cycle time: \textless10 seconds (total
time step 1-10) - ✅ Grasp success: Object lifted without slipping - ✅
Placement accuracy: \textless10mm from target center - ✅ No collisions
detected

\textbf{Concepts Demonstrated:} - Computer vision (detection, pose
estimation) - Inverse kinematics - Motion planning (collision-free
trajectory) - Grasp planning (force closure) - State machine (task
sequencing) - Coordinate transforms (camera → robot frame)

\textbf{Demo Video Deliverable:} 60-second video with screen capture
(RViz) + real robot

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{scenario-m2-multiple-objects-sequential-picking}{%
\subsubsection{Scenario M2: Multiple Objects (Sequential
Picking)}\label{scenario-m2-multiple-objects-sequential-picking}}

\textbf{Objective:} Pick 5 objects sequentially from cluttered workspace

\textbf{Setup:} - Objects: 5 colored cubes (red, blue, green, yellow,
black) randomly placed - Workspace: 600mm × 400mm area - Objects may
partially occlude each other

\textbf{Execution Steps:} 1. Start system 2. For each object (repeat 5
times): - Scan workspace - Detect all visible objects - Select
highest-confidence detection - Pick object - Place in designated zone
(indexed by color) 3. Report total time and success rate

\textbf{Success Criteria:} - ✅ All 5 objects picked and placed - ✅
Total cycle time: \textless60 seconds - ✅ No ``object not found''
errors - ✅ Objects placed in correct color-coded zones

\textbf{Concepts Demonstrated:} - Multi-object detection - Scene
understanding (occlusion handling) - Task planning (object
prioritization) - Real-time replanning (workspace changes after each
pick)

\textbf{Demo Video Deliverable:} 90-second time-lapse with analytics
overlay (objects remaining, cycle time)

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{scenario-m3-error-recovery-grasp-failure}{%
\subsubsection{Scenario M3: Error Recovery (Grasp
Failure)}\label{scenario-m3-error-recovery-grasp-failure}}

\textbf{Objective:} Demonstrate graceful error recovery when grasp fails

\textbf{Setup:} - Object: Slippery cylinder (low friction, challenging
grasp) - Intentionally weak grasp force (50\% of optimal)

\textbf{Execution Steps:} 1. Start pick sequence 2. Gripper grasps
cylinder with insufficient force 3. During lift, F/T sensor detects drop
(force spike → 0N) 4. System detects grasp failure 5. Robot returns to
pre-grasp position 6. System displays error: ``Grasp failed - Retrying
with increased force'' 7. Retry grasp with 100\% force 8. Successfully
lift and place object 9. Log failure event

\textbf{Success Criteria:} - ✅ Grasp failure detected within 500ms - ✅
Retry succeeds on 2nd attempt - ✅ No objects damaged - ✅ Error logged
with timestamp and cause

\textbf{Concepts Demonstrated:} - Force/torque sensing (grasp
verification) - Error detection (sensor-based) - Adaptive control
(adjust grasp force) - State machine (error state → recovery state)

\textbf{Demo Video Deliverable:} Split-screen (RViz + real robot)
showing failure and recovery

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{scenario-m4-calibration-wizard}{%
\subsubsection{Scenario M4: Calibration
Wizard}\label{scenario-m4-calibration-wizard}}

\textbf{Objective:} Demonstrate ease of camera-robot calibration

\textbf{Setup:} - Checkerboard pattern (8×6, 25mm squares) on table -
Camera uncalibrated (no prior hand-eye transform)

\textbf{Execution Steps:} 1. Launch calibration wizard 2. Wizard
prompts: ``Move robot to Position 1'' (pre-defined joint angles) 3.
Operator confirms, wizard captures image 4. Repeat for Positions 2-5
(different robot poses) 5. Wizard computes hand-eye transformation
matrix 6. Validation: Place known object, system predicts position 7.
Wizard displays error: ``Calibration error: 2.3mm (PASS)'' 8. Save
calibration to \texttt{/config/camera\_robot\_tf.yaml}

\textbf{Success Criteria:} - ✅ Calibration completes in \textless5
minutes - ✅ Reprojection error \textless5mm - ✅ Validation test passes
(object detected at correct position) - ✅ Calibration persists across
restarts

\textbf{Concepts Demonstrated:} - Hand-eye calibration (eye-to-hand
configuration) - Coordinate frame transformations - Usability (guided
wizard for non-experts)

\textbf{Demo Video Deliverable:} Screen capture of wizard UI, narrated
walkthrough

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{scenario-m5-safety-e-stop}{%
\subsubsection{Scenario M5: Safety
E-Stop}\label{scenario-m5-safety-e-stop}}

\textbf{Objective:} Demonstrate emergency stop functionality

\textbf{Setup:} - Robot executing pick sequence (mid-motion) - E-stop
button accessible

\textbf{Execution Steps:} 1. Start pick sequence 2. Robot moving toward
object (50\% into trajectory) 3. Operator presses E-stop button 4. Robot
halts immediately, motors de-energized 5. System displays: ``EMERGENCY
STOP - Press Reset to Continue'' 6. Operator releases E-stop, presses
``Reset'' 7. System prompts: ``Return to Home? (Y/N)'' 8. Operator
selects ``Y'', robot returns to home position 9. System ready for next
pick

\textbf{Success Criteria:} - ✅ Robot stops \textless100ms after E-stop
pressed - ✅ No drift after stop (brakes engaged) - ✅ Cannot restart
without deliberate reset action - ✅ Event logged with timestamp

\textbf{Concepts Demonstrated:} - Safety-rated E-stop (SIL 2) -
Real-time control loop (fast response) - State machine (emergency state)

\textbf{Demo Video Deliverable:} Real-time video showing E-stop
activation and recovery

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{should-have-demo-scenarios}{%
\subsection{2. Should Have Demo
Scenarios}\label{should-have-demo-scenarios}}

\hypertarget{scenario-s1-pose-variation-handling}{%
\subsubsection{Scenario S1: Pose Variation
Handling}\label{scenario-s1-pose-variation-handling}}

\textbf{Objective:} Pick objects in arbitrary orientations

\textbf{Setup:} - Objects: 3 rectangular boxes (100mm × 50mm × 30mm)
placed at different angles - Orientations: 0°, 45°, 90° around vertical
axis

\textbf{Execution Steps:} 1. For each object: - Detect object, estimate
6DoF pose (x,y,z,roll,pitch,yaw) - Compute aligned grasp (gripper
oriented to object's longest axis) - Pick and place 2. Display pose
estimates in RViz (TF frames)

\textbf{Success Criteria:} - ✅ All 3 objects picked regardless of
orientation - ✅ Pose estimation error: \textless5° rotation,
\textless5mm position - ✅ Grasp aligned to object geometry

\textbf{Concepts Demonstrated:} - 6DoF pose estimation (not just
centroid) - Grasp planning (orientation-aware) - TF visualization

\textbf{Demo Video Deliverable:} RViz visualization showing estimated
object frames overlaid on point cloud

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{scenario-s2-dynamic-conveyor-picking}{%
\subsubsection{Scenario S2: Dynamic Conveyor
Picking}\label{scenario-s2-dynamic-conveyor-picking}}

\textbf{Objective:} Pick objects from a moving conveyor belt

\textbf{Setup:} - Conveyor belt moving at 0.1 m/s (constant speed) -
Objects: 4 cubes placed at 200mm intervals - Camera: Mounted above belt,
tracking motion

\textbf{Execution Steps:} 1. Vision system tracks objects on belt
(optical flow / multi-frame tracking) 2. Predict object position at time
of grasp (t\_grasp = t\_detect + t\_plan + t\_move) 3. For each object:
- Estimate arrival time at pick zone - Pre-position robot (anticipatory
motion) - Pick object in motion (dynamic grasping) - Place in static
zone 4. Repeat until all objects picked

\textbf{Success Criteria:} - ✅ All 4 objects picked without stopping
conveyor - ✅ Grasp success rate \textgreater90\% - ✅ No collisions
with conveyor

\textbf{Concepts Demonstrated:} - Motion prediction (object tracking) -
Real-time planning (replanning during execution) - Trajectory execution
(moving target)

\textbf{Demo Video Deliverable:} Side view + top view (camera) showing
synchronized pick

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{scenario-s3-workspace-customization}{%
\subsubsection{Scenario S3: Workspace
Customization}\label{scenario-s3-workspace-customization}}

\textbf{Objective:} Demonstrate GUI for defining pick/place zones

\textbf{Setup:} - Blank workspace (table only) - RViz2 with interactive
markers

\textbf{Execution Steps:} 1. Operator opens zone definition tool in RViz
2. Draws pick zone (polygon tool, defines 2D boundary + height range) -
Pick zone: 400mm × 400mm, height: 0-200mm 3. Draws place zone (300mm ×
300mm, height: 50mm) 4. Draws exclusion zone (obstacle, 100mm × 100mm)
5. Save configuration to \texttt{zones.yaml} 6. Run pick-place with new
zones 7. System only picks from pick zone, places in place zone, avoids
exclusion

\textbf{Success Criteria:} - ✅ Zones defined in \textless2 minutes
(intuitive UI) - ✅ Configuration saved and reloaded correctly - ✅
Robot respects zone boundaries (no picks outside pick zone)

\textbf{Concepts Demonstrated:} - Planning scene management - Collision
objects (exclusion zones) - User-friendly configuration

\textbf{Demo Video Deliverable:} Screen capture of zone definition +
robot respecting zones

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{scenario-s4-multi-gripper-support}{%
\subsubsection{Scenario S4: Multi-Gripper
Support}\label{scenario-s4-multi-gripper-support}}

\textbf{Objective:} Swap gripper types and adapt grasp strategy

\textbf{Setup:} - Test with 2 gripper types: - Parallel jaw (for cubes,
boxes) - Suction (for flat, smooth objects like PCBs)

\textbf{Execution Steps:} 1. \textbf{Test 1: Parallel Jaw} - Object:
Cube - Grasp: Pinch grasp from sides - Success: Lifted with 20N force 2.
Swap gripper (manual or auto-tool-changer) 3. System detects gripper
change, loads suction gripper config 4. \textbf{Test 2: Suction} -
Object: Flat PCB (100mm × 100mm) - Grasp: Top-down suction - Success:
Vacuum pressure confirms seal (\textgreater0.5 bar)

\textbf{Success Criteria:} - ✅ Grasp planner adapts strategy per
gripper type - ✅ Both gripper types successfully pick objects - ✅
Gripper swap detected automatically (if using tool changer)

\textbf{Concepts Demonstrated:} - End-effector modularity - Grasp
planning (type-specific algorithms) - Hardware abstraction

\textbf{Demo Video Deliverable:} Side-by-side comparison of parallel jaw
vs suction grasps

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{scenario-s5-performance-dashboard}{%
\subsubsection{Scenario S5: Performance
Dashboard}\label{scenario-s5-performance-dashboard}}

\textbf{Objective:} Display real-time KPIs during operation

\textbf{Setup:} - Grafana dashboard open on separate monitor - System
running continuous pick-place loop (10 objects)

\textbf{Execution Steps:} 1. Start pick-place loop 2. Dashboard displays
(real-time updates): - Current state (SCAN, PICK, PLACE) - Objects
processed (counter) - Cycle time (current, average, p95) - Success rate
(\%) - Error log (scrolling list) - CPU/GPU utilization graphs 3.
Operator observes dashboard while robot works

\textbf{Success Criteria:} - ✅ Dashboard updates with \textless1 second
latency - ✅ Metrics accurate (verified against ground truth) - ✅
Graphs show historical trends (last 10 minutes)

\textbf{Concepts Demonstrated:} - Monitoring \& observability -
Prometheus + Grafana integration - Real-time data visualization

\textbf{Demo Video Deliverable:} Split-screen (robot + dashboard) for 60
seconds

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{scenario-s6-simulation-validation}{%
\subsubsection{Scenario S6: Simulation
Validation}\label{scenario-s6-simulation-validation}}

\textbf{Objective:} Run same workflow in simulation and real hardware

\textbf{Setup:} - Gazebo simulation with UR5e model, virtual camera,
physics engine - Identical object (cube) spawned in sim workspace

\textbf{Execution Steps:} 1. \textbf{In Simulation:} - Launch:
\texttt{ros2\ launch\ vision\_pickplace\ gazebo.launch.py} - Run
pick-place workflow - Record: cycle time, trajectory, grasp success 2.
\textbf{On Real Hardware:} - Launch:
\texttt{ros2\ launch\ vision\_pickplace\ real\_robot.launch.py} - Run
identical workflow - Record same metrics 3. Compare results (sim vs
real)

\textbf{Success Criteria:} - ✅ Simulation runs without errors - ✅
Cycle time difference \textless20\% (sim vs real) - ✅ Trajectory
similar (verified via joint plots) - ✅ Grasp success in both
environments

\textbf{Concepts Demonstrated:} - Simulation fidelity (Gazebo) -
Sim-to-real transfer - Testing without hardware risk

\textbf{Demo Video Deliverable:} Side-by-side video (Gazebo + real
robot) synchronized

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{may-have-demo-scenarios-advanced}{%
\subsection{3. May Have Demo Scenarios
(Advanced)}\label{may-have-demo-scenarios-advanced}}

\hypertarget{scenario-a1-bin-picking-with-pile-segmentation}{%
\subsubsection{Scenario A1: Bin Picking with Pile
Segmentation}\label{scenario-a1-bin-picking-with-pile-segmentation}}

\textbf{Objective:} Pick objects from a cluttered bin (random pile)

\textbf{Setup:} - Bin: 400mm × 400mm × 200mm deep - Objects: 20 cubes
randomly dumped (overlapping, various orientations)

\textbf{Execution Steps:} 1. Capture point cloud of bin 2. Segment
individual objects (clustering, region growing) 3. Identify graspable
objects (top layer, unoccluded) 4. Pick top object 5. Repeat until bin
empty (re-scan after each pick)

\textbf{Success Criteria:} - ✅ All 20 objects picked (may take multiple
scans) - ✅ No collisions with bin walls - ✅ Success rate
\textgreater85\% (some failures expected with occlusions)

\textbf{Concepts Demonstrated:} - 3D point cloud processing (PCL) -
Segmentation (clustering) - Iterative scene understanding

\textbf{Demo Video Deliverable:} Time-lapse (accelerated 5x) showing bin
emptying

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{scenario-a2-collaborative-operation-human-in-loop}{%
\subsubsection{Scenario A2: Collaborative Operation
(Human-in-Loop)}\label{scenario-a2-collaborative-operation-human-in-loop}}

\textbf{Objective:} Safely operate with human present in workspace

\textbf{Setup:} - Human (volunteer) standing near workspace -
Vision-based human detection (YOLO person class) - Safety zones defined
(inner: stop zone, outer: slow zone)

\textbf{Execution Steps:} 1. Robot executing pick-place at normal speed
(100\%) 2. Human approaches workspace (enters outer zone) 3. System
detects human, robot slows to 50\% speed 4. Human enters inner zone 5.
Robot stops immediately (\textless100ms) 6. System displays: ``Human
detected - Waiting'' 7. Human exits zone 8. After 2-second timeout,
robot resumes

\textbf{Success Criteria:} - ✅ Human detected within 500ms - ✅ Robot
stops before human contact - ✅ Speed reduction smooth (no jerks) - ✅
System resumes automatically when safe

\textbf{Concepts Demonstrated:} - Human-robot collaboration (ISO/TS
15066) - Vision-based safety (redundant to laser scanners) - Adaptive
speed control

\textbf{Demo Video Deliverable:} Wide-angle video showing human and
robot interaction

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{scenario-a3-ai-model-retraining-loop}{%
\subsubsection{Scenario A3: AI Model Retraining
Loop}\label{scenario-a3-ai-model-retraining-loop}}

\textbf{Objective:} Demonstrate model improvement from production data

\textbf{Setup:} - System collects 1000 pick images over 1 week
(auto-logged) - Data scientist uses collected data to retrain YOLO

\textbf{Execution Steps:} 1. \textbf{Data Collection:} - System logs all
RGB-D images + labels (bounding boxes) - Store in
\texttt{/data/production\_logs/} 2. \textbf{Retraining:} - Load data
into Label Studio (review annotations) - Train YOLOv8 with fine-tuning
(10 epochs) - Export to ONNX 3. \textbf{Deployment:} - Upload new model
to robot - A/B test: 50\% traffic to old model, 50\% to new - Compare
accuracy (new model: 96\% mAP, old: 92\%) 4. \textbf{Rollout:} - New
model promoted to 100\% traffic

\textbf{Success Criteria:} - ✅ Data collection pipeline works
autonomously - ✅ Retraining improves accuracy (\textgreater2\% mAP
gain) - ✅ A/B test infrastructure functional - ✅ Deployment seamless
(no downtime)

\textbf{Concepts Demonstrated:} - ML Ops (training pipeline, model
registry) - Continuous improvement - A/B testing

\textbf{Demo Video Deliverable:} Screencast of MLflow experiments +
before/after accuracy comparison

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{scenario-a4-multi-robot-coordination}{%
\subsubsection{Scenario A4: Multi-Robot
Coordination}\label{scenario-a4-multi-robot-coordination}}

\textbf{Objective:} Two robots working collaboratively in shared
workspace

\textbf{Setup:} - 2× UR5e robots with shared workspace (overlapping
reach) - 10 objects to be sorted (5 per robot)

\textbf{Execution Steps:} 1. Task allocator assigns objects to robots
based on proximity 2. Both robots execute pick-place concurrently 3.
Collision avoidance ensures no robot-robot collision 4. If paths
conflict, lower-priority robot yields (waits)

\textbf{Success Criteria:} - ✅ All 10 objects sorted in \textless30
seconds (faster than single robot) - ✅ No collisions between robots -
✅ Load balanced (5 objects per robot)

\textbf{Concepts Demonstrated:} - Multi-robot planning - Conflict
resolution - Distributed task allocation

\textbf{Demo Video Deliverable:} Overhead view showing both robots
working

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{scenario-a5-predictive-maintenance}{%
\subsubsection{Scenario A5: Predictive
Maintenance}\label{scenario-a5-predictive-maintenance}}

\textbf{Objective:} Predict motor failure before it happens

\textbf{Setup:} - Logged data: motor temperatures, vibration, cycle
counts (simulated 6 months) - Trained ML model (LSTM) predicts remaining
useful life (RUL)

\textbf{Execution Steps:} 1. System monitors motor health in real-time
2. Model predicts: ``Joint 3 RUL: 14 days'' (based on temperature trend)
3. Alert triggered: ``Maintenance recommended for Joint 3'' 4.
Maintenance scheduled (proactive, before failure) 5. Post-maintenance:
RUL resets to nominal

\textbf{Success Criteria:} - ✅ Prediction accuracy \textgreater80\%
(validated on historical data) - ✅ Alert triggers 2 weeks before
predicted failure - ✅ No unexpected downtime

\textbf{Concepts Demonstrated:} - Predictive analytics (ML for
maintenance) - Time-series forecasting (LSTM) - Proactive maintenance

\textbf{Demo Video Deliverable:} Grafana dashboard showing RUL trends +
alert

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{demo-scenario-summary-table}{%
\subsection{4. Demo Scenario Summary
Table}\label{demo-scenario-summary-table}}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1239}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1239}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1239}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1416}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.4867}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\textbf{Scenario}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\textbf{Category}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\textbf{Duration}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\textbf{Complexity}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\textbf{Key Concepts}
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
M1 & Must Have & 60 sec & Low & Vision, IK, motion planning, grasp
planning \\
M2 & Must Have & 90 sec & Medium & Multi-object detection, task
planning \\
M3 & Must Have & 90 sec & Medium & Error recovery, adaptive control, F/T
sensing \\
M4 & Must Have & 5 min & Medium & Hand-eye calibration, transforms \\
M5 & Must Have & 30 sec & Low & Safety, E-stop, state machine \\
S1 & Should Have & 60 sec & Medium & 6DoF pose estimation, oriented
grasping \\
S2 & Should Have & 120 sec & High & Dynamic picking, motion
prediction \\
S3 & Should Have & 5 min & Low & Workspace customization, planning
scene \\
S4 & Should Have & 90 sec & Medium & Multi-gripper support, hardware
abstraction \\
S5 & Should Have & 60 sec & Low & Monitoring, Grafana, observability \\
S6 & Should Have & 90 sec & Medium & Simulation, Gazebo, sim-to-real \\
A1 & May Have & 5 min & High & Bin picking, point cloud segmentation \\
A2 & May Have & 90 sec & High & Human-robot collaboration, safety
zones \\
A3 & May Have & 10 min & High & ML Ops, model retraining, A/B testing \\
A4 & May Have & 60 sec & Very High & Multi-robot coordination, conflict
resolution \\
A5 & May Have & 5 min & High & Predictive maintenance, time-series
forecasting \\
\end{longtable}

\textbf{Total Demo Time:} \textasciitilde40 minutes (all scenarios)

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{demo-event-planning}{%
\subsection{5. Demo Event Planning}\label{demo-event-planning}}

\hypertarget{suggested-demo-flow-30-minute-presentation}{%
\subsubsection{5.1 Suggested Demo Flow (30-minute
presentation)}\label{suggested-demo-flow-30-minute-presentation}}

\textbf{Segment 1: Introduction (5 min)} - System overview (slide deck)
- Problem statement and value proposition - Live system walkthrough
(components: robot, camera, control PC)

\textbf{Segment 2: Core Functionality (15 min)} - \textbf{M1:} Basic
pick-place (2 min live + narration) - \textbf{M2:} Multiple objects (2
min) - \textbf{M3:} Error recovery (2 min) - \textbf{M4:} Calibration
wizard (5 min, interactive) - \textbf{M5:} E-stop (1 min)

\textbf{Segment 3: Advanced Features (8 min)} - \textbf{S1:} Pose
variation (video, 1 min) - \textbf{S2:} Conveyor picking (video, 2 min)
- \textbf{S5:} Dashboard (live, 2 min) - \textbf{A2:} Collaborative
operation (video, 3 min)

\textbf{Segment 4: Q\&A (2 min)}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{demo-checklist}{%
\subsubsection{5.2 Demo Checklist}\label{demo-checklist}}

\textbf{Pre-Demo (1 hour before):} - {[} {]} Power on robot, camera,
control PC - {[} {]} Verify network connectivity (ROS2 topics visible) -
{[} {]} Run health check (all sensors green) - {[} {]} Load demo objects
in workspace - {[} {]} Open dashboards (RViz, Grafana) on presentation
display - {[} {]} Test E-stop button

\textbf{During Demo:} - {[} {]} Narrate each step clearly (explain what
system is doing) - {[} {]} Pause for questions between scenarios - {[}
{]} If failure occurs: explain error, show recovery (don't hide issues)
- {[} {]} Point out key visualizations (bounding boxes, trajectories, TF
frames)

\textbf{Post-Demo:} - {[} {]} Collect feedback (what impressed? what
needs improvement?) - {[} {]} Record demo metrics (cycle times,
accuracy, uptime) - {[} {]} Update demo scenarios based on feedback

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{demo-risk-mitigation}{%
\subsection{6. Demo Risk Mitigation}\label{demo-risk-mitigation}}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.3678}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.6322}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\textbf{Risk}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\textbf{Mitigation}
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Network failure (ROS2 comms) & Pre-check network, have backup
recordings \\
Camera not detecting object & Backup objects (high-contrast,
known-good) \\
Grasp failure during demo & Tune gripper force beforehand, test 10×
pre-demo \\
Robot E-stop during demo & Test E-stop recovery procedure beforehand \\
Laptop/display issues & Backup laptop with pre-loaded software \\
Power outage & UPS for critical systems \\
Software crash & Restart procedure documented, \textless2 min
recovery \\
\end{longtable}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{demo-metrics-to-collect}{%
\subsection{7. Demo Metrics to Collect}\label{demo-metrics-to-collect}}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3293}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.2195}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.4512}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\textbf{Metric}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\textbf{Target}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\textbf{Measurement Method}
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Cycle time (M1) & \textless10 sec & Timestamp start to finish \\
Multi-object throughput (M2) & \textgreater5 picks/min & Total time /
objects picked \\
Grasp success rate & \textgreater95\% & Successful picks / total
attempts \\
Calibration time (M4) & \textless5 min & Stopwatch \\
E-stop response time (M5) & \textless100 ms & Oscilloscope (button press
→ stop) \\
Detection accuracy & \textgreater95\% mAP & Test on labeled dataset \\
Pose estimation error & \textless5mm, \textless5° & Ground truth from
CMM \\
Dashboard update latency & \textless1 sec & Wall clock vs dashboard
timestamp \\
\end{longtable}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{audience-specific-demo-variants}{%
\subsection{8. Audience-Specific Demo
Variants}\label{audience-specific-demo-variants}}

\hypertarget{for-technical-audience-engineers-researchers}{%
\subsubsection{For Technical Audience (Engineers,
Researchers)}\label{for-technical-audience-engineers-researchers}}

\textbf{Emphasize:} - Architecture (show ROS2 node graph) - Algorithms
(explain YOLO, IK solver, RRT*) - Code walkthrough (brief, show key
modules) - Performance benchmarks (latency, throughput)

\textbf{Recommended Scenarios:} M1, M2, M3, S1, S6, A3

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{for-business-audience-managers-executives}{%
\subsubsection{For Business Audience (Managers,
Executives)}\label{for-business-audience-managers-executives}}

\textbf{Emphasize:} - ROI (cycle time improvement, labor savings) - Ease
of use (M4 calibration wizard) - Reliability (M3 error recovery, uptime
metrics) - Dashboard (S5 KPI visualization)

\textbf{Recommended Scenarios:} M1, M2, M3, M4, S5

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{for-safety-officers-regulators}{%
\subsubsection{For Safety Officers /
Regulators}\label{for-safety-officers-regulators}}

\textbf{Emphasize:} - Safety compliance (ISO 10218, ISO/TS 15066) -
E-stop functionality (M5) - Human detection (A2) - Audit logs (immutable
logs, retention)

\textbf{Recommended Scenarios:} M5, A2, plus walk through safety
documentation

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{for-customers-end-users}{%
\subsubsection{For Customers / End
Users}\label{for-customers-end-users}}

\textbf{Emphasize:} - Ease of deployment (M4 calibration) - Reliability
(M3 error recovery) - Performance (M2 throughput) - Support (mention
24/7 support SLA)

\textbf{Recommended Scenarios:} M1, M2, M3, M4, S3, S5

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{demo-video-production-guidelines}{%
\subsection{9. Demo Video Production
Guidelines}\label{demo-video-production-guidelines}}

\textbf{For Each Scenario:} 1. \textbf{Introduction Slide (5 sec):}
Scenario name, objective 2. \textbf{Setup Overview (5 sec):} Wide shot
of workspace, label objects 3. \textbf{Execution (variable):} Multiple
camera angles: - Robot close-up (gripper action) - Workspace overhead
(full scene) - Screen capture (RViz, dashboard) 4. \textbf{Results (5
sec):} Success/fail indicators, metrics overlay 5. \textbf{Conclusion
Slide (3 sec):} Key takeaway

\textbf{Technical Specs:} - Resolution: 1080p (1920×1080) - Frame rate:
30 fps - Format: MP4 (H.264 codec) - Audio: Narration (clear voice,
background music optional) - Graphics: Lower-third text overlay with
scenario name

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{conclusion}{%
\subsection{10. Conclusion}\label{conclusion}}

This demo scenario collection provides: - \textbf{5 Must Have
scenarios:} Core functionality validation - \textbf{6 Should Have
scenarios:} Production-readiness features - \textbf{5 May Have
scenarios:} Advanced capabilities showcase - \textbf{Total demo time:}
40 minutes (all scenarios) - \textbf{Audience-specific variants:}
Tailored for technical, business, safety, customer audiences -
\textbf{Risk mitigation:} Backup plans for common failures -
\textbf{Metrics to collect:} Quantitative validation data

\textbf{Next Steps:} 1. Implement Must Have scenarios first (MVP) 2.
Record high-quality demo videos for remote presentations 3. Create
interactive demo for trade shows (allow audience participation) 4.
Gather feedback and refine scenarios iteratively

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{Document Status:} ✅ Complete \textbf{Last Updated:} 2025-10-18
\textbf{Author:} Product \& Demo Team \textbf{Review Status:} Pending
Review

\end{document}
