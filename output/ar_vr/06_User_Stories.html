<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>06 User Stories - AR/VR Documentation</title>
    <script src="https://aframe.io/releases/1.5.0/aframe.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <style>
        body {
            margin: 0;
            overflow: hidden;
            font-family: 'Arial', sans-serif;
        }

        #overlay {
            position: fixed;
            top: 20px;
            left: 20px;
            right: 20px;
            background: rgba(0, 0, 0, 0.8);
            color: white;
            padding: 30px;
            border-radius: 15px;
            max-height: 80vh;
            overflow-y: auto;
            z-index: 1000;
            backdrop-filter: blur(10px);
        }

        #overlay h1 {
            color: #667eea;
            margin-bottom: 20px;
            font-size: 2.5em;
        }

        #overlay h2 {
            color: #764ba2;
            margin-top: 30px;
            font-size: 1.8em;
        }

        #overlay code {
            background: rgba(102, 126, 234, 0.2);
            padding: 2px 6px;
            border-radius: 4px;
            color: #a5b4fc;
        }

        #overlay pre {
            background: rgba(0, 0, 0, 0.5);
            padding: 15px;
            border-radius: 8px;
            overflow-x: auto;
            border-left: 4px solid #667eea;
        }

        #overlay pre code {
            background: transparent;
        }

        #overlay table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }

        #overlay th {
            background: linear-gradient(135deg, #667eea, #764ba2);
            padding: 12px;
            text-align: left;
        }

        #overlay td {
            padding: 10px 12px;
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
        }

        #controls {
            position: fixed;
            bottom: 30px;
            left: 50%;
            transform: translateX(-50%);
            display: flex;
            gap: 15px;
            z-index: 1001;
        }

        .control-btn {
            background: linear-gradient(135deg, #667eea, #764ba2);
            color: white;
            border: none;
            padding: 15px 30px;
            border-radius: 50px;
            cursor: pointer;
            font-size: 1em;
            font-weight: 600;
            box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4);
            transition: all 0.3s;
        }

        .control-btn:hover {
            transform: translateY(-3px);
            box-shadow: 0 6px 20px rgba(102, 126, 234, 0.6);
        }

        .info-panel {
            position: fixed;
            top: 20px;
            right: 20px;
            background: rgba(0, 0, 0, 0.8);
            color: white;
            padding: 20px;
            border-radius: 10px;
            z-index: 1000;
            backdrop-filter: blur(10px);
            max-width: 300px;
        }

        .info-panel h3 {
            color: #667eea;
            margin-bottom: 10px;
        }

        .info-panel p {
            margin: 5px 0;
            font-size: 0.9em;
        }
    </style>
</head>
<body>
    <div id="overlay" style="display: none;">
        <div id="content"></div>
    </div>

    <div class="info-panel">
        <h3>ðŸ¥½ VR Documentation</h3>
        <p><strong>06 User Stories</strong></p>
        <p>Use WASD to move</p>
        <p>Mouse to look around</p>
        <p>Click 'Toggle Doc' to read</p>
    </div>

    <div id="controls">
        <button class="control-btn" onclick="toggleOverlay()">ðŸ“„ Toggle Doc</button>
        <button class="control-btn" onclick="enterVR()">ðŸ¥½ Enter VR</button>
        <button class="control-btn" onclick="resetView()">ðŸ”„ Reset View</button>
    </div>

    <a-scene background="color: #000">
        <!-- Sky with gradient -->
        <a-sky color="#1a1a2e"></a-sky>

        <!-- Ambient lighting -->
        <a-light type="ambient" color="#667eea" intensity="0.5"></a-light>
        <a-light type="directional" color="#FFF" intensity="0.8" position="2 4 -3"></a-light>
        <a-light type="point" color="#764ba2" intensity="1" position="0 3 0"></a-light>

        <!-- Floor grid -->
        <a-plane position="0 0 0" rotation="-90 0 0" width="20" height="20"
                 color="#0f0f23" roughness="0.8" metalness="0.2"
                 shader="flat" repeat="10 10"></a-plane>

        <!-- Documentation panels floating in 3D space -->
        <a-entity id="doc-environment" position="0 1.6 -3">
            <!-- Main title panel -->
            <a-plane position="0 2 0" rotation="0 0 0" width="8" height="1.5"
                     color="#667eea" opacity="0.9">
                <a-text value="06 User Stories" align="center" color="#FFF"
                        position="0 0 0.01" width="8" font="roboto"></a-text>
            </a-plane>

            <!-- Floating data panels in circular arrangement -->
            <a-entity id="panel-1" position="-3 0 0">
                <a-box color="#667eea" opacity="0.7" width="1.5" height="2" depth="0.1"
                       roughness="0.3" metalness="0.6"
                       animation="property: rotation; to: 0 360 0; loop: true; dur: 20000">
                    <a-text value="PDF\nFormat" align="center" color="#FFF"
                            position="0 0.5 0.06" width="2"></a-text>
                    <a-text value="Complete\nDocumentation" align="center" color="#CCC"
                            position="0 -0.3 0.06" width="1.5"></a-text>
                </a-box>
            </a-entity>

            <a-entity id="panel-2" position="3 0 0">
                <a-box color="#764ba2" opacity="0.7" width="1.5" height="2" depth="0.1"
                       roughness="0.3" metalness="0.6"
                       animation="property: rotation; to: 0 360 0; loop: true; dur: 20000; dir: reverse">
                    <a-text value="Interactive\n3D View" align="center" color="#FFF"
                            position="0 0.5 0.06" width="2"></a-text>
                    <a-text value="Immersive\nExperience" align="center" color="#CCC"
                            position="0 -0.3 0.06" width="1.5"></a-text>
                </a-box>
            </a-entity>

            <a-entity id="panel-3" position="0 0 -2">
                <a-cylinder color="#f093fb" opacity="0.7" radius="0.75" height="2"
                           roughness="0.3" metalness="0.6"
                           animation="property: position; to: 0 0.5 -2; loop: true; dur: 3000; dir: alternate; easing: easeInOutSine">
                    <a-text value="VisionBot\nProject" align="center" color="#FFF"
                            position="0 0.5 0.76" width="2"></a-text>
                </a-cylinder>
            </a-entity>

            <!-- Floating stats spheres -->
            <a-sphere position="-1.5 1.5 -1" radius="0.3" color="#10b981" opacity="0.8"
                     animation="property: position; to: -1.5 2 -1; loop: true; dur: 2000; dir: alternate">
                <a-text value="99.2%\nSuccess" align="center" color="#FFF"
                        position="0 0 0.31" width="1.2"></a-text>
            </a-sphere>

            <a-sphere position="1.5 1.5 -1" radius="0.3" color="#f59e0b" opacity="0.8"
                     animation="property: position; to: 1.5 2 -1; loop: true; dur: 2500; dir: alternate">
                <a-text value="93.5%\nOEE" align="center" color="#FFF"
                        position="0 0 0.31" width="1.2"></a-text>
            </a-sphere>
        </a-entity>

        <!-- Camera with controls -->
        <a-entity id="camera-rig" position="0 0 0">
            <a-camera id="main-camera" wasd-controls look-controls>
                <a-cursor color="#667eea" fuse="true" fuse-timeout="1500"></a-cursor>
            </a-camera>
        </a-entity>

        <!-- Particle effect -->
        <a-entity position="0 2.5 -5">
            <a-entity geometry="primitive: sphere; radius: 0.05"
                     material="color: #667eea; emissive: #667eea; emissiveIntensity: 0.5"
                     animation="property: position; to: 0 4 -5; loop: true; dur: 4000; easing: linear"></a-entity>
        </a-entity>
    </a-scene>

    <script>
        // Convert markdown to HTML
        const markdown = `# User Stories - Vision-Based Pick and Place System

## Overview
This document contains **user stories** organized by persona, mapped to core robotics concepts, and prioritized using the MoSCoW method (Must have, Should have, Could have, Won't have).

---

## 1. Personas

### 1.1 Primary Personas

| **Persona**              | **Role**                          | **Goals**                                      | **Pain Points**                     |
|--------------------------|-----------------------------------|------------------------------------------------|-------------------------------------|
| **Alex (Operator)**      | Production floor operator         | Run system efficiently, monitor status, handle errors | Complex interfaces, unclear error messages |
| **Jordan (Integrator)**  | Robotics system integrator        | Deploy and configure system, calibrate sensors | Poor documentation, difficult setup |
| **Sam (Engineer)**       | Software/robotics engineer        | Develop new features, debug issues, optimize  | Lack of modularity, hard-to-trace bugs |
| **Morgan (Manager)**     | Production/operations manager     | Maximize uptime, throughput, ROI              | Lack of visibility, slow cycle times |
| **Casey (Maintenance)**  | Maintenance technician            | Perform routine maintenance, diagnose faults  | No diagnostic tools, unclear procedures |
| **Taylor (Data Scientist)** | AI/ML engineer                 | Train models, improve detection accuracy      | Limited labeled data, model drift |

### 1.2 Secondary Personas

| **Persona**              | **Role**                          | **Goals**                                      |
|--------------------------|-----------------------------------|------------------------------------------------|
| **Riley (Safety Officer)** | Safety compliance manager       | Ensure system safety, compliance with standards |
| **Drew (Customer)**      | End customer/client               | Reliable system, good support, fast ROI        |

---

## 2. User Stories by Persona

### 2.1 Alex (Operator)

#### Story 1: Basic Operation (Must Have)
**As** an operator,
**I want** to start and stop the pick-and-place system with a single button press,
**So that** I can operate the system without technical knowledge.

**Acceptance Criteria:**
- Single "Start" button initiates the full workflow (scan â†’ pick â†’ place)
- "Stop" button safely halts all motion within 1 second
- Emergency stop button cuts power to motors immediately (<100ms)
- Visual indicator (green/red LED) shows system status

**Priority:** Must Have
**Story Points:** 3
**Related Concepts:** State Machine, Task Orchestration, Safety

---

#### Story 2: Real-Time Monitoring (Must Have)
**As** an operator,
**I want** to see a live dashboard showing robot status, throughput, and errors,
**So that** I can quickly identify and address issues.

**Acceptance Criteria:**
- Dashboard displays: current state, objects processed, cycle time, error log
- Updates in real-time (<1 second latency)
- Color-coded alerts (green=OK, yellow=warning, red=error)
- Accessible via web browser or touchscreen HMI

**Priority:** Must Have
**Story Points:** 5
**Related Concepts:** UI/Visualization, Monitoring & Logging

---

#### Story 3: Error Recovery Guidance (Should Have)
**As** an operator,
**I want** clear instructions when an error occurs (e.g., "Object not detected - check lighting"),
**So that** I can resolve issues without calling engineering support.

**Acceptance Criteria:**
- Error messages are human-readable (no error codes alone)
- Suggested recovery actions displayed (e.g., "Retry", "Adjust camera", "Call support")
- One-click retry mechanism for transient errors
- Error log with timestamp and severity

**Priority:** Should Have
**Story Points:** 5
**Related Concepts:** Error Handling, State Machine

---

#### Story 4: Manual Intervention Mode (Should Have)
**As** an operator,
**I want** to manually jog the robot to a safe position if automatic recovery fails,
**So that** I can clear obstructions or reposition objects.

**Acceptance Criteria:**
- Teach pendant or joystick interface available
- Robot moves at reduced speed (10% max) in manual mode
- Collision detection active during manual jog
- Auto-returns to home position after manual intervention

**Priority:** Should Have
**Story Points:** 8
**Related Concepts:** Motion Control, Safety

---

### 2.2 Jordan (Integrator)

#### Story 5: Guided Calibration (Must Have)
**As** an integrator,
**I want** a step-by-step wizard to calibrate the camera-to-robot transformation,
**So that** I can deploy the system without deep robotics knowledge.

**Acceptance Criteria:**
- Wizard guides through: robot positioning, checkerboard placement, image capture
- Automatic computation of hand-eye calibration matrix
- Validation step (detect known object, verify position accuracy <5mm)
- Calibration results saved and version-controlled

**Priority:** Must Have
**Story Points:** 13
**Related Concepts:** Camera-Robot Calibration, Coordinate Transforms

---

#### Story 6: Workspace Configuration (Must Have)
**As** an integrator,
**I want** to define pick and place zones via a GUI (draw polygons in RViz),
**So that** I can customize the system for different factory layouts.

**Acceptance Criteria:**
- Interactive zone definition in RViz2 (draw 2D polygons, set heights)
- Save/load zone configurations (YAML files)
- System only picks/places within defined zones
- Collision objects automatically added to planning scene

**Priority:** Must Have
**Story Points:** 8
**Related Concepts:** Motion Planning, Collision Avoidance

---

#### Story 7: Gripper Selection (Should Have)
**As** an integrator,
**I want** to select from pre-configured gripper types (parallel jaw, suction, custom),
**So that** I can adapt to different object types.

**Acceptance Criteria:**
- Dropdown menu to select gripper type
- System adjusts grasp planning algorithm based on selection
- Gripper parameters (max force, stroke) configurable
- Test grasp function to validate configuration

**Priority:** Should Have
**Story Points:** 8
**Related Concepts:** Grasp Planning, End-Effector Control

---

#### Story 8: Simulation Before Deployment (Should Have)
**As** an integrator,
**I want** to test the system in Gazebo simulation before running on real hardware,
**So that** I can validate configuration without risk.

**Acceptance Criteria:**
- Launch files for both simulation and real hardware
- Simulated camera provides synthetic images (textured objects)
- Motion planning and control identical in sim and real
- "Sim-to-real" checklist ensures parity

**Priority:** Should Have
**Story Points:** 13
**Related Concepts:** Simulation, Testing

---

### 2.3 Sam (Engineer)

#### Story 9: Modular Architecture (Must Have)
**As** an engineer,
**I want** the system to use ROS2 nodes with well-defined interfaces (topics, services, actions),
**So that** I can develop and test modules independently.

**Acceptance Criteria:**
- Each subsystem (vision, planning, control) is a separate ROS2 package
- Interfaces documented in README with message types
- Launch files support launching individual nodes for testing
- Unit tests for each node (>80% code coverage)

**Priority:** Must Have
**Story Points:** 21
**Related Concepts:** ROS2 Architecture, Software Design

---

#### Story 10: Live Parameter Tuning (Should Have)
**As** an engineer,
**I want** to adjust PID gains and motion parameters via dynamic reconfigure,
**So that** I can optimize performance without recompiling code.

**Acceptance Criteria:**
- ROS2 parameters for: PID gains, trajectory speed limits, detection thresholds
- Changes take effect immediately (no restart required)
- Parameter server maintains history (rollback support)
- Save tuned parameters to YAML for persistence

**Priority:** Should Have
**Story Points:** 5
**Related Concepts:** Control Tuning, ros2_control

---

#### Story 11: Debugging Tools (Should Have)
**As** an engineer,
**I want** to record ROS2 bags of failed pick attempts and replay them,
**So that** I can debug issues offline.

**Acceptance Criteria:**
- Auto-record bags on error (last 30 seconds of data)
- Bags include: images, joint states, TF, planning scene
- Replay mode allows stepping through time
- Annotate bags with error descriptions

**Priority:** Should Have
**Story Points:** 8
**Related Concepts:** Logging, Debugging

---

#### Story 12: Custom AI Model Integration (Could Have)
**As** an engineer,
**I want** to swap the object detection model (e.g., YOLOv8 â†’ custom model),
**So that** I can adapt to new object types.

**Acceptance Criteria:**
- Model loader accepts ONNX or TensorRT formats
- Configuration file specifies model path, input size, classes
- Inference node automatically adjusts preprocessing
- Benchmark tool compares model performance

**Priority:** Could Have
**Story Points:** 13
**Related Concepts:** AI/ML, Object Detection

---

### 2.4 Morgan (Manager)

#### Story 13: Performance Dashboard (Must Have)
**As** a manager,
**I want** a high-level dashboard showing throughput, uptime, and error rates,
**So that** I can track KPIs and report to stakeholders.

**Acceptance Criteria:**
- Dashboard shows: picks/hour, uptime %, error rate, cycle time (avg/p95)
- Historical trends (daily, weekly, monthly)
- Export reports as PDF or CSV
- Alerts when KPIs fall below thresholds

**Priority:** Must Have
**Story Points:** 13
**Related Concepts:** Monitoring, Analytics

---

#### Story 14: ROI Calculator (Should Have)
**As** a manager,
**I want** to see a cost-benefit analysis (labor saved vs system cost),
**So that** I can justify the investment.

**Acceptance Criteria:**
- Input: labor cost/hour, picks/day (manual), system cost
- Output: payback period, NPV, IRR
- Compare scenarios (1 robot vs 2 robots, etc.)
- Interactive what-if analysis

**Priority:** Should Have
**Story Points:** 8
**Related Concepts:** Business Case, ROI

---

#### Story 15: Predictive Maintenance (Could Have)
**As** a manager,
**I want** alerts when components (motors, gripper) are predicted to fail,
**So that** I can schedule maintenance proactively.

**Acceptance Criteria:**
- Monitor motor temperatures, cycle counts, vibration
- ML model predicts remaining useful life (RUL)
- Alert when RUL < 2 weeks
- Maintenance schedule auto-generated

**Priority:** Could Have
**Story Points:** 21
**Related Concepts:** Predictive Maintenance, AI/ML

---

### 2.5 Casey (Maintenance)

#### Story 16: Diagnostic Tools (Must Have)
**As** a maintenance technician,
**I want** a health check tool that tests all sensors and actuators,
**So that** I can quickly diagnose faults.

**Acceptance Criteria:**
- One-click health check runs in <5 minutes
- Tests: camera (image quality), encoders (position accuracy), F/T sensor (calibration), motors (torque)
- Pass/fail report with detailed errors
- Guidance for replacing failed components

**Priority:** Must Have
**Story Points:** 13
**Related Concepts:** Testing, Diagnostics

---

#### Story 17: Maintenance Schedule (Should Have)
**As** a maintenance technician,
**I want** a calendar showing upcoming maintenance tasks (e.g., "Lubricate joints every 1000 hours"),
**So that** I can plan preventive maintenance.

**Acceptance Criteria:**
- Maintenance tasks defined per component
- Calendar view shows next due date
- Email/SMS reminders 1 week before due
- Log completed tasks (date, technician, notes)

**Priority:** Should Have
**Story Points:** 8
**Related Concepts:** Maintenance Planning

---

#### Story 18: Spare Parts Inventory (Could Have)
**As** a maintenance technician,
**I want** the system to track spare parts usage and reorder when low,
**So that** I don't run out of critical components.

**Acceptance Criteria:**
- Inventory database (part name, quantity, reorder level)
- Alert when quantity < reorder level
- Integration with procurement system (auto-generate PO)
- Track part usage per robot

**Priority:** Could Have
**Story Points:** 13
**Related Concepts:** Inventory Management

---

### 2.6 Taylor (Data Scientist)

#### Story 19: Data Collection Pipeline (Must Have)
**As** a data scientist,
**I want** to automatically log images and labels (bounding boxes, poses) for every pick,
**So that** I can build a dataset for model retraining.

**Acceptance Criteria:**
- Log RGB-D images, ground-truth poses (from robot FK)
- Metadata: timestamp, object class, success/failure
- Storage: HDF5 or organized folder structure
- Option to anonymize data (blur backgrounds)

**Priority:** Must Have
**Story Points:** 8
**Related Concepts:** Data Management, AI/ML

---

#### Story 20: Model Retraining Workflow (Should Have)
**As** a data scientist,
**I want** a Jupyter notebook template for retraining the detection model on new data,
**So that** I can improve accuracy without starting from scratch.

**Acceptance Criteria:**
- Template includes: data loading, train/val split, training loop, evaluation
- Pre-configured hyperparameters (learning rate, batch size)
- MLflow integration for experiment tracking
- Export trained model to ONNX/TensorRT

**Priority:** Should Have
**Story Points:** 13
**Related Concepts:** AI/ML, Training Pipeline

---

#### Story 21: A/B Testing for Models (Could Have)
**As** a data scientist,
**I want** to deploy two models in parallel (A/B test) and compare their performance,
**So that** I can validate improvements before full rollout.

**Acceptance Criteria:**
- Route 50% of requests to model A, 50% to model B
- Log inference results for both models
- Compare metrics: accuracy, latency, error rate
- Gradual rollout (10% â†’ 50% â†’ 100%)

**Priority:** Could Have
**Story Points:** 13
**Related Concepts:** AI/ML, Experimentation

---

### 2.7 Riley (Safety Officer)

#### Story 22: Safety Zone Monitoring (Must Have)
**As** a safety officer,
**I want** the robot to stop immediately if a human enters the workspace,
**So that** we comply with ISO 10218 and prevent injuries.

**Acceptance Criteria:**
- Vision-based human detection (YOLO person class)
- Safety-rated laser scanner (optional, for redundancy)
- Robot stops within 100ms of detection
- Cannot restart until human leaves zone and "Resume" is pressed

**Priority:** Must Have
**Story Points:** 13
**Related Concepts:** Safety, Human-Robot Interaction

---

#### Story 23: Audit Trail (Must Have)
**As** a safety officer,
**I want** immutable logs of all safety events (E-stop, collisions, zone breaches),
**So that** I can investigate incidents and ensure compliance.

**Acceptance Criteria:**
- Logs include: timestamp, event type, trigger source, robot state
- Logs cannot be edited or deleted (append-only)
- Retention: 5 years
- Export logs for audits (PDF report)

**Priority:** Must Have
**Story Points:** 8
**Related Concepts:** Logging, Security, Compliance

---

#### Story 24: Force Limiting (Should Have)
**As** a safety officer,
**I want** the robot to limit contact forces to <150N (per ISO/TS 15066),
**So that** collaborative operation is safe.

**Acceptance Criteria:**
- F/T sensor monitors contact forces in real-time
- Robot stops if force exceeds 150N
- Configurable force limits per zone (lower limits near humans)
- Monthly force calibration check

**Priority:** Should Have
**Story Points:** 13
**Related Concepts:** Safety, Force Control

---

### 2.8 Drew (Customer)

#### Story 25: Easy Deployment (Must Have)
**As** a customer,
**I want** the system to be operational within 1 day of delivery,
**So that** I minimize downtime.

**Acceptance Criteria:**
- Pre-configured for common use cases (e.g., bin picking, kitting)
- Calibration wizard completes in <1 hour
- Training materials: video tutorials, quick start guide
- Remote support available during setup

**Priority:** Must Have
**Story Points:** 21
**Related Concepts:** Deployment, Documentation

---

#### Story 26: Vendor Support (Must Have)
**As** a customer,
**I want** 24/7 support with <4 hour response time for critical issues,
**So that** I can maintain production uptime.

**Acceptance Criteria:**
- Support portal with ticketing system
- Phone/email/chat support channels
- SLA: critical issues <4 hours, normal issues <24 hours
- Remote diagnostics (VPN access with customer approval)

**Priority:** Must Have
**Story Points:** N/A (operational)
**Related Concepts:** Support, Maintenance

---

#### Story 27: Performance Guarantee (Should Have)
**As** a customer,
**I want** a guarantee that the system achieves â‰¥99% grasp success on my objects,
**So that** I trust the system will meet my needs.

**Acceptance Criteria:**
- Pre-deployment testing on customer's objects (100 picks)
- Performance report with success rate, cycle time
- Money-back guarantee if <99% success after tuning
- Quarterly performance reviews

**Priority:** Should Have
**Story Points:** N/A (business process)
**Related Concepts:** Performance, SLA

---

## 3. User Stories Mapped to Core Robotics Concepts

| **Robotics Concept**        | **User Stories**                                      |
|-----------------------------|-------------------------------------------------------|
| Computer Vision             | 2, 5, 12, 19, 22                                      |
| Kinematics (FK/IK)          | 4, 5, 6, 19                                           |
| Motion Planning             | 6, 8, 9                                               |
| Grasp Planning              | 7, 12                                                 |
| Control & Execution         | 1, 4, 10                                              |
| State Machine               | 1, 3                                                  |
| Sensor Fusion & Calibration | 5, 16                                                 |
| Coordinate Transforms       | 5, 6                                                  |
| Collision Avoidance         | 4, 6                                                  |
| Safety & HRI                | 1, 22, 24                                             |
| Monitoring & Logging        | 2, 11, 23                                             |
| AI/ML                       | 12, 15, 19, 20, 21, 22                                |
| Simulation                  | 8                                                     |
| Performance Optimization    | 10, 13, 27                                            |

---

## 4. Prioritization Summary (MoSCoW)

### Must Have (17 stories)
Critical for MVP and core functionality:
1, 2, 5, 6, 9, 13, 16, 19, 22, 23, 25, 26

### Should Have (10 stories)
Important for usability and production-readiness:
3, 4, 7, 8, 10, 11, 14, 17, 20, 24

### Could Have (5 stories)
Nice-to-have, added if time permits:
12, 15, 18, 21, 27

### Won't Have (This Release)
Deferred to future versions:
- Multi-robot coordination
- Cloud-based analytics
- Mobile app (iOS/Android)

---

## 5. Epic Grouping

### Epic 1: Core Operation
Stories: 1, 2, 3, 4
**Goal:** Enable operators to run the system reliably

### Epic 2: System Integration
Stories: 5, 6, 7, 8
**Goal:** Enable integrators to deploy and configure

### Epic 3: Developer Experience
Stories: 9, 10, 11, 12
**Goal:** Enable engineers to develop and debug

### Epic 4: Business Intelligence
Stories: 13, 14, 15
**Goal:** Provide visibility and ROI to management

### Epic 5: Maintenance & Support
Stories: 16, 17, 18
**Goal:** Enable proactive and reactive maintenance

### Epic 6: AI/ML Pipeline
Stories: 19, 20, 21
**Goal:** Enable continuous model improvement

### Epic 7: Safety & Compliance
Stories: 22, 23, 24
**Goal:** Ensure safe operation and regulatory compliance

### Epic 8: Customer Success
Stories: 25, 26, 27
**Goal:** Ensure customer satisfaction and adoption

---

## 6. User Story Estimation

### Story Points Distribution
- **Small (3-5 points):** 7 stories (Quick wins, 1-2 weeks)
- **Medium (8-13 points):** 13 stories (Standard features, 2-4 weeks)
- **Large (21 points):** 3 stories (Complex features, 4-8 weeks)

### Total Effort Estimate
- **Must Have:** ~150 story points (â‰ˆ30 weeks with 1 dev, â‰ˆ15 weeks with 2 devs)
- **Should Have:** ~80 story points (â‰ˆ16 weeks)
- **Could Have:** ~60 story points (â‰ˆ12 weeks)

**Estimated MVP Timeline:** 6 months (2 developers) for Must Have + Should Have

---

## 7. Acceptance Testing Scenarios

### Scenario 1: End-to-End Pick-Place (Story 1, 2)
**Given** 10 objects on a table
**When** operator presses "Start"
**Then** system picks and places all 10 objects within 30 seconds
**And** dashboard shows 100% success rate

### Scenario 2: Error Recovery (Story 3)
**Given** an occluded object (not detectable)
**When** system scans the workspace
**Then** error message displays "Object not detected - check for occlusions"
**And** operator can press "Retry" or "Skip"

### Scenario 3: Calibration (Story 5)
**Given** a new robot installation
**When** integrator runs calibration wizard
**Then** hand-eye transform computed within 5 minutes
**And** validation detects object position with <5mm error

### Scenario 4: Safety Stop (Story 22)
**Given** robot is moving toward pick position
**When** human enters safety zone
**Then** robot stops within 100ms
**And** alarm sounds, "Resume" button required to continue

---

## 8. Non-Functional Requirements Derived from Stories

| **NFR Category**      | **Requirement**                                      | **Source Stories** |
|-----------------------|------------------------------------------------------|--------------------|
| **Performance**       | Cycle time â‰¤2 sec/object                             | 13, 27             |
| **Reliability**       | Uptime â‰¥99.5%                                        | 13, 26             |
| **Usability**         | Operator training â‰¤4 hours                           | 1, 2, 3            |
| **Scalability**       | Support 1-10 robots on same network                  | 9                  |
| **Security**          | Authentication required for config changes           | 23                 |
| **Maintainability**   | Code coverage â‰¥80%                                   | 9                  |
| **Portability**       | Support Ubuntu 22.04, ROS2 Humble                    | 9                  |
| **Safety**            | Comply with ISO 10218, ISO/TS 15066                  | 22, 24             |

---

## 9. Traceability Matrix

| **User Story** | **System Requirement** | **Design Component**      | **Test Case**          |
|----------------|------------------------|---------------------------|------------------------|
| 1              | REQ-001: Start/Stop    | Task Orchestrator FSM     | TC-001: Start button   |
| 2              | REQ-002: Dashboard     | Grafana + Prometheus      | TC-002: Dashboard load |
| 5              | REQ-005: Calibration   | Hand-Eye Calibration Node | TC-005: Calib accuracy |
| 9              | REQ-009: Modularity    | ROS2 Package Structure    | TC-009: Unit tests     |
| 22             | REQ-022: Safety Zone   | Human Detection Node      | TC-022: Stop on detect |

---

## 10. Conclusion

This user story collection provides:
- **27 user stories** covering 8 personas
- **Mapped to core robotics concepts** (vision, planning, control, safety, AI)
- **Prioritized** using MoSCoW (17 Must Have, 10 Should Have, 5 Could Have)
- **Grouped into 8 epics** for sprint planning
- **Estimated at 290 story points** total (~58 weeks with 1 developer)
- **Acceptance criteria** and test scenarios for validation

**Next Steps:**
1. Refine story points with development team
2. Create detailed tasks for each story (subtasks in Jira/Linear)
3. Sprint planning: allocate stories to 2-week sprints
4. Continuous backlog grooming based on feedback

---

**Document Status:** âœ… Complete
**Last Updated:** 2025-10-18
**Author:** Product Management Team
**Review Status:** Pending Stakeholder Review
`;

        document.addEventListener('DOMContentLoaded', function() {
            const contentDiv = document.getElementById('content');
            contentDiv.innerHTML = marked.parse(markdown);
        });

        function toggleOverlay() {
            const overlay = document.getElementById('overlay');
            overlay.style.display = overlay.style.display === 'none' ? 'block' : 'none';
        }

        function enterVR() {
            const scene = document.querySelector('a-scene');
            if (scene.is('vr-mode')) {
                scene.exitVR();
            } else {
                scene.enterVR();
            }
        }

        function resetView() {
            const cameraRig = document.getElementById('camera-rig');
            cameraRig.setAttribute('position', '0 0 0');
            const camera = document.getElementById('main-camera');
            camera.setAttribute('rotation', '0 0 0');
        }

        // Keyboard shortcuts
        document.addEventListener('keydown', function(e) {
            if (e.key === 'd' || e.key === 'D') {
                toggleOverlay();
            } else if (e.key === 'r' || e.key === 'R') {
                resetView();
            }
        });
    </script>
</body>
</html>